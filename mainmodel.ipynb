{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-27T04:47:18.218Z",
     "iopub.execute_input": "2025-02-27T04:44:57.190608Z",
     "iopub.status.busy": "2025-02-27T04:44:57.190270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-27 04:45:00,052] A new study created in memory with name: no-name-12a5740f-1d32-4576-b03e-9196fe126cd6\n",
      "Epoch 1/6:   1%|          | 1/131 [01:39<3:34:44, 99.11s/batch, loss=8.9971]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # For normalization\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "# ---------------------------------\n",
    "# Dataset Setup and Augmentation\n",
    "# ---------------------------------\n",
    "train_dir = \"/kaggle/input/asccsasca/Medicinal plant dataset\"\n",
    "if not os.path.exists(train_dir):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {train_dir}\")\n",
    "\n",
    "def stratified_split_dataset(dataset, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits a dataset into train, validation, and test subsets using stratified sampling.\n",
    "    \"\"\"\n",
    "    targets = np.array(dataset.targets)\n",
    "    indices = np.arange(len(targets))\n",
    "    \n",
    "    # First, split off the test set.\n",
    "    sss_test = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=42)\n",
    "    for train_val_idx, test_idx in sss_test.split(indices, targets):\n",
    "        pass\n",
    "\n",
    "    # Now split train_val into train and validation sets.\n",
    "    train_val_targets = targets[train_val_idx]\n",
    "    # Adjust validation ratio relative to the remaining samples.\n",
    "    val_relative_ratio = val_ratio / (1 - test_ratio)\n",
    "    sss_val = StratifiedShuffleSplit(n_splits=1, test_size=val_relative_ratio, random_state=42)\n",
    "    for train_idx, val_idx in sss_val.split(np.arange(len(train_val_targets)), train_val_targets):\n",
    "        pass\n",
    "\n",
    "    # Map back to original indices.\n",
    "    train_indices = train_val_idx[train_idx]\n",
    "    val_indices = train_val_idx[val_idx]\n",
    "    \n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_idx)\n",
    "    return train_subset, val_subset, test_subset\n",
    "\n",
    "# Enhanced training augmentation (with added brightness/contrast)\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, fill_value=0, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "# For validation and test, use a simpler transform.\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        return self.transform(image=image)['image']\n",
    "\n",
    "# Create the full dataset using the training transform.\n",
    "full_dataset = datasets.ImageFolder(root=train_dir, transform=AlbumentationsTransform(train_transform))\n",
    "# Perform stratified splitting.\n",
    "train_dataset, val_dataset, test_dataset = stratified_split_dataset(full_dataset, val_ratio=0.2, test_ratio=0.1)\n",
    "# Optionally override the transform for validation and test subsets:\n",
    "train_dataset.dataset.transform = AlbumentationsTransform(train_transform)\n",
    "val_dataset.dataset.transform   = AlbumentationsTransform(val_transform)\n",
    "test_dataset.dataset.transform  = AlbumentationsTransform(val_transform)\n",
    "\n",
    "# Standard loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# ============================================================\n",
    "# Additional Improvements for Highly Imbalanced Datasets\n",
    "# ============================================================\n",
    "# 1️⃣ Reweighted Loss Functions: Define a custom Focal Loss.\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, weight=None, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight  # tensor of shape (num_classes,)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = -F.cross_entropy(inputs, targets, weight=self.weight, reduction=\"none\")\n",
    "        pt = torch.exp(logpt)\n",
    "        loss = -((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# 2️⃣ Oversampling / Undersampling: Compute sample weights and create a WeightedRandomSampler.\n",
    "# Get targets for the training subset.\n",
    "train_targets = [full_dataset.targets[i] for i in train_dataset.indices]\n",
    "train_targets = np.array(train_targets)\n",
    "unique_classes = np.unique(train_targets)\n",
    "class_sample_count = np.array([np.sum(train_targets == t) for t in unique_classes])\n",
    "# Inverse frequency weights:\n",
    "class_weights = 1. / class_sample_count\n",
    "# For each training sample:\n",
    "samples_weight = np.array([class_weights[t] for t in train_targets])\n",
    "samples_weight = torch.from_numpy(samples_weight).float()\n",
    "# Create the WeightedRandomSampler.\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "oversample_sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)\n",
    "# Create a balanced loader.\n",
    "train_loader_balanced = DataLoader(train_dataset, batch_size=32, sampler=oversample_sampler, num_workers=4)\n",
    "\n",
    "# 4️⃣ Logits Adjustment During Inference: Function to adjust logits using class priors.\n",
    "def adjust_logits(logits, class_priors):\n",
    "    # Subtract the log of class priors from the logits.\n",
    "    log_priors = torch.log(torch.tensor(class_priors, device=logits.device))\n",
    "    return logits - log_priors\n",
    "\n",
    "# ============================================================\n",
    "# SimAM Attention Module\n",
    "# ============================================================\n",
    "class SimAM(nn.Module):\n",
    "    def __init__(self, e_lambda=1e-4):\n",
    "        super(SimAM, self).__init__()\n",
    "        self.e_lambda = e_lambda\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        mu = x.mean(dim=[2,3], keepdim=True)\n",
    "        var = ((x - mu) ** 2).sum(dim=[2,3], keepdim=True) / (x.size(2) * x.size(3) - 1)\n",
    "        attention = 1.0 / (var + self.e_lambda)\n",
    "        return x * attention\n",
    "\n",
    "# ============================================================\n",
    "# Multi-Scale Attention Module using Depthwise Convolutions + SimAM\n",
    "# ============================================================\n",
    "class MultiScaleAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(MultiScaleAttention, self).__init__()\n",
    "        self.conv3 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, groups=channels)\n",
    "        self.conv5 = nn.Conv2d(channels, channels, kernel_size=5, padding=2, groups=channels)\n",
    "        self.conv7 = nn.Conv2d(channels, channels, kernel_size=7, padding=3, groups=channels)\n",
    "        self.fuse_conv = nn.Conv2d(channels * 3, channels, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.simam = SimAM()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out3 = self.conv3(x)\n",
    "        out5 = self.conv5(x)\n",
    "        out7 = self.conv7(x)\n",
    "        out = torch.cat([out3, out5, out7], dim=1)\n",
    "        out = self.fuse_conv(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.simam(out)\n",
    "        return out\n",
    "\n",
    "# ============================================================\n",
    "# Squeeze-and-Excitation (SE) Block for Gated Fusion\n",
    "# ============================================================\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, 1)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.adaptive_avg_pool2d(x, 1)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y))\n",
    "        return x * y\n",
    "\n",
    "# ============================================================\n",
    "# Hybrid Model (ConvNeXt Base + EfficientNetV2-S) with Dynamic Feature Fusion, Self-Distillation & Contrastive Projection\n",
    "# ============================================================\n",
    "class HybridPlantClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HybridPlantClassifier, self).__init__()\n",
    "        # Load pretrained feature extractors.\n",
    "        # Modified to use 'convnext_base' for ConvNeXt and 'efficientnetv2_s' for EfficientNetV2-S.\n",
    "        self.convnext = timm.create_model('convnext_base', pretrained=True, features_only=True)\n",
    "        self.efficientnet = timm.create_model('efficientnetv2_s', pretrained=False, features_only=True)\n",
    "        self.fused_channels = 512\n",
    "\n",
    "        # Project features to a common channel dimension.\n",
    "        self.convnext_proj = nn.Conv2d(self.convnext.feature_info[-1]['num_chs'], \n",
    "                                       self.fused_channels, kernel_size=1, bias=False)\n",
    "        self.efficientnet_proj = nn.Conv2d(self.efficientnet.feature_info[-1]['num_chs'], \n",
    "                                           self.fused_channels, kernel_size=1, bias=False)\n",
    "        # Dynamic fusion by concatenation and a gated (SEBlock) 1x1 convolution.\n",
    "        self.fusion_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.fused_channels * 2, self.fused_channels, kernel_size=1, bias=False),\n",
    "            SEBlock(self.fused_channels)\n",
    "        )\n",
    "        \n",
    "        # Multi-Scale Attention.\n",
    "        self.attention = MultiScaleAttention(self.fused_channels)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(self.fused_channels, num_classes)\n",
    "        # Contrastive projection head.\n",
    "        self.contrastive_head = nn.Sequential(\n",
    "            nn.Linear(self.fused_channels, self.fused_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.fused_channels, 128)\n",
    "        )\n",
    "        # Self-distillation branch (auxiliary head).\n",
    "        self.distill_head = nn.Sequential(\n",
    "            nn.Linear(self.fused_channels, self.fused_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.fused_channels, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, return_features=False):\n",
    "        feat_convnext = self.convnext_proj(self.convnext(x)[-1])\n",
    "        feat_effnet   = self.efficientnet_proj(self.efficientnet(x)[-1])\n",
    "        # Concatenate and fuse features.\n",
    "        fused = torch.cat([feat_convnext, feat_effnet], dim=1)\n",
    "        fused = self.fusion_conv(fused)\n",
    "        fused = self.attention(fused)\n",
    "        pooled = self.avgpool(fused).view(fused.size(0), -1)\n",
    "        logits = self.classifier(pooled)\n",
    "        if return_features:\n",
    "            # Generate contrastive embeddings.\n",
    "            embedding = self.contrastive_head(pooled)\n",
    "            embedding = F.normalize(embedding, dim=1)\n",
    "            # Obtain distillation logits.\n",
    "            distill_logits = self.distill_head(pooled)\n",
    "            return logits, embedding, distill_logits\n",
    "        return logits\n",
    "\n",
    "# ============================================================\n",
    "# MixUp and CutMix Functions (with tunable alpha)\n",
    "# ============================================================\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size, C, H, W = x.size()\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    r_x = np.random.randint(W)\n",
    "    r_y = np.random.randint(H)\n",
    "    r_w = int(W * np.sqrt(1 - lam))\n",
    "    r_h = int(H * np.sqrt(1 - lam))\n",
    "    x1 = np.clip(r_x - r_w // 2, 0, W)\n",
    "    y1 = np.clip(r_y - r_h // 2, 0, H)\n",
    "    x2 = np.clip(r_x + r_w // 2, 0, W)\n",
    "    y2 = np.clip(r_y + r_h // 2, 0, H)\n",
    "    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
    "    y_a, y_b = y, y[index]\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ============================================================\n",
    "# Supervised Contrastive Loss (SupConLoss)\n",
    "# ============================================================\n",
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised Contrastive Loss as described in \"Supervised Contrastive Learning\" (Khosla et al.)\n",
    "    Expects features of shape [batch_size, n_views, feature_dim]. For a single view, unsqueeze dimension 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]  # For a single view, n_views = 1\n",
    "        features = features.view(batch_size * n_views, -1)\n",
    "        labels = labels.repeat(n_views)\n",
    "        similarity_matrix = torch.div(torch.matmul(features, features.T), self.temperature)\n",
    "        logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)\n",
    "        logits = similarity_matrix - logits_max.detach()\n",
    "        mask = torch.eq(labels.unsqueeze(1), labels.unsqueeze(0)).float().to(device)\n",
    "        # Remove self-comparisons from the mask.\n",
    "        logits_mask = torch.scatter(torch.ones_like(mask), 1,\n",
    "                                    torch.arange(batch_size * n_views).view(-1, 1).to(device), 0)\n",
    "        mask = mask * logits_mask\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)\n",
    "        mask_sum = mask.sum(1)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask_sum + 1e-12)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss\n",
    "\n",
    "# ============================================================\n",
    "# Test-Time Augmentation (TTA) Function\n",
    "# ============================================================\n",
    "def predict_with_tta(model, image, tta_transforms, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for transform in tta_transforms:\n",
    "            aug = transform(image=image)['image']\n",
    "            aug = aug.unsqueeze(0).to(device)\n",
    "            output = model(aug)\n",
    "            predictions.append(torch.softmax(output, dim=1).cpu().numpy())\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "tta_transforms = [\n",
    "    A.Compose([A.Resize(224, 224), ToTensorV2()]),\n",
    "    A.Compose([A.Resize(224, 224), A.HorizontalFlip(p=1.0), ToTensorV2()]),\n",
    "    # Add more TTA variations as desired.\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Training Function with Contrastive Loss, Self-Distillation & Dynamic LR\n",
    "# ============================================================\n",
    "def train_model(config, train_loader, val_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_classes = len(full_dataset.classes)\n",
    "    model = HybridPlantClassifier(num_classes=num_classes).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config['epochs'])\n",
    "    \n",
    "    # Choose loss function based on config.\n",
    "    # Options: \"ce\", \"focal\", \"weighted_ce\"\n",
    "    loss_type = config.get(\"loss_type\", \"ce\")\n",
    "    if loss_type == \"focal\":\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = FocalLoss(gamma=2.0, weight=class_weights_tensor, reduction=\"mean\")\n",
    "    elif loss_type == \"weighted_ce\":\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    supcon_loss_fn = SupConLoss(temperature=0.07)\n",
    "    contrastive_weight = config.get(\"contrastive_weight\", 1.0)\n",
    "    distill_weight = config.get(\"distill_weight\", 0.5)\n",
    "    mixup_alpha = config.get(\"mixup_alpha\", 1.0)\n",
    "    cutmix_alpha = config.get(\"cutmix_alpha\", 1.0)\n",
    "    num_epochs = config['epochs']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # --- Classification Branch with MixUp/CutMix ---\n",
    "            if np.random.rand() < 0.5:\n",
    "                mixed_images, y_a, y_b, lam = mixup_data(images, labels, alpha=mixup_alpha)\n",
    "            else:\n",
    "                mixed_images, y_a, y_b, lam = cutmix_data(images, labels, alpha=cutmix_alpha)\n",
    "            outputs = model(mixed_images)\n",
    "            loss_ce = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "\n",
    "            # --- Contrastive Branch and Self-Distillation using Original Images ---\n",
    "            _, embeddings, distill_logits = model(images, return_features=True)\n",
    "            embeddings = embeddings.unsqueeze(1)  # Shape: [batch, 1, feature_dim]\n",
    "            loss_contrast = supcon_loss_fn(embeddings, labels)\n",
    "            loss_distill = F.kl_div(F.log_softmax(distill_logits, dim=1),\n",
    "                                    F.softmax(outputs, dim=1), reduction='batchmean')\n",
    "            \n",
    "            total_loss = loss_ce + contrastive_weight * loss_contrast + distill_weight * loss_distill\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            train_loss += total_loss.item() * batch_size\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            # Using proxy ground truth from mixup/cutmix.\n",
    "            train_correct += (preds == y_a).sum().item()\n",
    "            train_total += batch_size\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(y_a.cpu().numpy())\n",
    "            pbar.set_postfix(loss=f\"{total_loss.item():.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss = train_loss / train_total\n",
    "        train_acc = train_correct / train_total\n",
    "        train_f1 = f1_score(train_labels, train_preds, average=\"weighted\")\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "\n",
    "        # --- Validation Phase (without MixUp/CutMix) ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                batch_size = labels.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += batch_size\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        avg_val_loss = val_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\\n\")\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# Evaluation Function (Test Set) with Optional Logits Adjustment\n",
    "# ============================================================\n",
    "def evaluate_model(model, loader, adjust_logits_flag=False, class_priors=None, return_acc=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            if adjust_logits_flag and (class_priors is not None):\n",
    "                outputs = adjust_logits(outputs, class_priors)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs)\n",
    "    acc = (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    if return_acc:\n",
    "        return acc\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\\n\")\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    all_labels_bin = label_binarize(all_labels, classes=range(len(full_dataset.classes)))\n",
    "    fpr, tpr, _ = roc_curve(all_labels_bin.ravel(), np.array(all_probs).ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    config = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True),\n",
    "        \"epochs\": 6,\n",
    "        \"contrastive_weight\": trial.suggest_float(\"contrastive_weight\", 0.5, 2.0),\n",
    "        \"distill_weight\": trial.suggest_float(\"distill_weight\", 0.1, 1.0),\n",
    "        \"mixup_alpha\": trial.suggest_float(\"mixup_alpha\", 0.5, 2.0),\n",
    "        \"cutmix_alpha\": trial.suggest_float(\"cutmix_alpha\", 0.5, 2.0),\n",
    "        \"loss_type\": trial.suggest_categorical(\"loss_type\", [\"ce\", \"focal\", \"weighted_ce\"])\n",
    "    }\n",
    "    # For tuning, we use the standard train_loader.\n",
    "    model = train_model(config, train_loader, val_loader)\n",
    "    val_acc = evaluate_model(model, val_loader, return_acc=True)\n",
    "    trial.report(val_acc, step=0)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    return val_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(), pruner=HyperbandPruner())\n",
    "study.optimize(objective, n_trials=8)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "\n",
    "\n",
    "# Use the best hyperparameters from Optuna and increase epochs.\n",
    "best_config = study.best_params.copy()\n",
    "best_config[\"epochs\"] = 30  # Increase epochs as desired.\n",
    "\n",
    "# ----- Two-Stage Training -----\n",
    "# Stage 1: Train on balanced (oversampled) data.\n",
    "print(\"Stage 1 Training on Balanced Data (Oversampled):\")\n",
    "model_stage1 = train_model(best_config, train_loader_balanced, val_loader)\n",
    "\n",
    "# Stage 2: Fine-tune on the original (imbalanced) distribution.\n",
    "print(\"Stage 2 Fine-Tuning on Original Distribution:\")\n",
    "model_final = train_model(best_config, train_loader, val_loader)\n",
    "\n",
    "# Compute class priors from training targets for logits adjustment.\n",
    "total_samples = len(train_targets)\n",
    "class_priors = [np.sum(train_targets == i) / total_samples for i in range(len(unique_classes))]\n",
    "print(\"Class Priors:\", class_priors)\n",
    "\n",
    "evaluate_model(model_final, test_loader, adjust_logits_flag=True, class_priors=class_priors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # For normalization\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "# ---------------------------------\n",
    "# Dataset Setup and Augmentation\n",
    "# ---------------------------------\n",
    "train_dir = \"/kaggle/input/asccsasca/Medicinal plant dataset\"\n",
    "if not os.path.exists(train_dir):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {train_dir}\")\n",
    "\n",
    "def stratified_split_dataset(dataset, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits a dataset into train, validation, and test subsets using stratified sampling.\n",
    "    \"\"\"\n",
    "    targets = np.array(dataset.targets)\n",
    "    indices = np.arange(len(targets))\n",
    "    \n",
    "    # First, split off the test set.\n",
    "    sss_test = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=42)\n",
    "    for train_val_idx, test_idx in sss_test.split(indices, targets):\n",
    "        pass\n",
    "\n",
    "    # Now split train_val into train and validation sets.\n",
    "    train_val_targets = targets[train_val_idx]\n",
    "    # Adjust validation ratio relative to the remaining samples.\n",
    "    val_relative_ratio = val_ratio / (1 - test_ratio)\n",
    "    sss_val = StratifiedShuffleSplit(n_splits=1, test_size=val_relative_ratio, random_state=42)\n",
    "    for train_idx, val_idx in sss_val.split(np.arange(len(train_val_targets)), train_val_targets):\n",
    "        pass\n",
    "\n",
    "    # Map back to original indices.\n",
    "    train_indices = train_val_idx[train_idx]\n",
    "    val_indices = train_val_idx[val_idx]\n",
    "    \n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "    test_subset = Subset(dataset, test_idx)\n",
    "    return train_subset, val_subset, test_subset\n",
    "\n",
    "# Enhanced training augmentation (with added brightness/contrast)\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, fill_value=0, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "# For validation and test, use a simpler transform.\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        return self.transform(image=image)['image']\n",
    "\n",
    "# Create the full dataset using the training transform.\n",
    "full_dataset = datasets.ImageFolder(root=train_dir, transform=AlbumentationsTransform(train_transform))\n",
    "# Perform stratified splitting.\n",
    "train_dataset, val_dataset, test_dataset = stratified_split_dataset(full_dataset, val_ratio=0.2, test_ratio=0.1)\n",
    "# Override the transform for validation and test subsets:\n",
    "train_dataset.dataset.transform = AlbumentationsTransform(train_transform)\n",
    "val_dataset.dataset.transform   = AlbumentationsTransform(val_transform)\n",
    "test_dataset.dataset.transform  = AlbumentationsTransform(val_transform)\n",
    "\n",
    "# Standard loaders (using train_loader without any balancing sampler)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# ============================================================\n",
    "# Additional Modules (Attention, Fusion, etc.)\n",
    "# ============================================================\n",
    "\n",
    "# 1️⃣ Custom Focal Loss (kept here in case you want to try it)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = -F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(logpt)\n",
    "        loss = -((1 - pt) ** self.gamma) * logpt\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# 3️⃣ Logits Adjustment During Inference: Function to adjust logits using class priors.\n",
    "def adjust_logits(logits, class_priors):\n",
    "    # Subtract the log of class priors from the logits.\n",
    "    log_priors = torch.log(torch.tensor(class_priors, device=logits.device))\n",
    "    return logits - log_priors\n",
    "\n",
    "# ============================================================\n",
    "# SimAM Attention Module\n",
    "# ============================================================\n",
    "class SimAM(nn.Module):\n",
    "    def __init__(self, e_lambda=1e-4):\n",
    "        super(SimAM, self).__init__()\n",
    "        self.e_lambda = e_lambda\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        mu = x.mean(dim=[2,3], keepdim=True)\n",
    "        var = ((x - mu) ** 2).sum(dim=[2,3], keepdim=True) / (x.size(2) * x.size(3) - 1)\n",
    "        attention = 1.0 / (var + self.e_lambda)\n",
    "        return x * attention\n",
    "\n",
    "# ============================================================\n",
    "# Multi-Scale Attention Module using Depthwise Convolutions + SimAM\n",
    "# ============================================================\n",
    "class MultiScaleAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(MultiScaleAttention, self).__init__()\n",
    "        self.conv3 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, groups=channels)\n",
    "        self.conv5 = nn.Conv2d(channels, channels, kernel_size=5, padding=2, groups=channels)\n",
    "        self.conv7 = nn.Conv2d(channels, channels, kernel_size=7, padding=3, groups=channels)\n",
    "        self.fuse_conv = nn.Conv2d(channels * 3, channels, kernel_size=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.simam = SimAM()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out3 = self.conv3(x)\n",
    "        out5 = self.conv5(x)\n",
    "        out7 = self.conv7(x)\n",
    "        out = torch.cat([out3, out5, out7], dim=1)\n",
    "        out = self.fuse_conv(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.simam(out)\n",
    "        return out\n",
    "\n",
    "# ============================================================\n",
    "# Squeeze-and-Excitation (SE) Block for Gated Fusion\n",
    "# ============================================================\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, 1)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.adaptive_avg_pool2d(x, 1)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y))\n",
    "        return x * y\n",
    "\n",
    "# ============================================================\n",
    "# Hybrid Model (ConvNeXt Base + EfficientNetV2-S) with Dynamic Feature Fusion, Self-Distillation & Contrastive Projection\n",
    "# ============================================================\n",
    "class HybridPlantClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HybridPlantClassifier, self).__init__()\n",
    "        # Load pretrained feature extractors.\n",
    "        self.convnext = timm.create_model('convnext_base', pretrained=True, features_only=True)\n",
    "        self.efficientnet = timm.create_model('efficientnetv2_s', pretrained=False, features_only=True)\n",
    "        self.fused_channels = 512\n",
    "\n",
    "        # Project features to a common channel dimension.\n",
    "        self.convnext_proj = nn.Conv2d(self.convnext.feature_info[-1]['num_chs'], \n",
    "                                       self.fused_channels, kernel_size=1, bias=False)\n",
    "        self.efficientnet_proj = nn.Conv2d(self.efficientnet.feature_info[-1]['num_chs'], \n",
    "                                           self.fused_channels, kernel_size=1, bias=False)\n",
    "        # Dynamic fusion by concatenation and a gated (SEBlock) 1x1 convolution.\n",
    "        self.fusion_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.fused_channels * 2, self.fused_channels, kernel_size=1, bias=False),\n",
    "            SEBlock(self.fused_channels)\n",
    "        )\n",
    "        \n",
    "        # Multi-Scale Attention.\n",
    "        self.attention = MultiScaleAttention(self.fused_channels)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(self.fused_channels, num_classes)\n",
    "        # Contrastive projection head.\n",
    "        self.contrastive_head = nn.Sequential(\n",
    "            nn.Linear(self.fused_channels, self.fused_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.fused_channels, 128)\n",
    "        )\n",
    "        # Self-distillation branch (auxiliary head).\n",
    "        self.distill_head = nn.Sequential(\n",
    "            nn.Linear(self.fused_channels, self.fused_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.fused_channels, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, return_features=False):\n",
    "        feat_convnext = self.convnext_proj(self.convnext(x)[-1])\n",
    "        feat_effnet   = self.efficientnet_proj(self.efficientnet(x)[-1])\n",
    "        # Concatenate and fuse features.\n",
    "        fused = torch.cat([feat_convnext, feat_effnet], dim=1)\n",
    "        fused = self.fusion_conv(fused)\n",
    "        fused = self.attention(fused)\n",
    "        pooled = self.avgpool(fused).view(fused.size(0), -1)\n",
    "        logits = self.classifier(pooled)\n",
    "        if return_features:\n",
    "            # Generate contrastive embeddings.\n",
    "            embedding = self.contrastive_head(pooled)\n",
    "            embedding = F.normalize(embedding, dim=1)\n",
    "            # Obtain distillation logits.\n",
    "            distill_logits = self.distill_head(pooled)\n",
    "            return logits, embedding, distill_logits\n",
    "        return logits\n",
    "\n",
    "# ============================================================\n",
    "# MixUp and CutMix Functions (with tunable alpha)\n",
    "# ============================================================\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size, C, H, W = x.size()\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    r_x = np.random.randint(W)\n",
    "    r_y = np.random.randint(H)\n",
    "    r_w = int(W * np.sqrt(1 - lam))\n",
    "    r_h = int(H * np.sqrt(1 - lam))\n",
    "    x1 = np.clip(r_x - r_w // 2, 0, W)\n",
    "    y1 = np.clip(r_y - r_h // 2, 0, H)\n",
    "    x2 = np.clip(r_x + r_w // 2, 0, W)\n",
    "    y2 = np.clip(r_y + r_h // 2, 0, H)\n",
    "    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
    "    y_a, y_b = y, y[index]\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ============================================================\n",
    "# Supervised Contrastive Loss (SupConLoss)\n",
    "# ============================================================\n",
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Supervised Contrastive Loss as described in \"Supervised Contrastive Learning\" (Khosla et al.)\n",
    "    Expects features of shape [batch_size, n_views, feature_dim]. For a single view, unsqueeze dimension 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        n_views = features.shape[1]  # For a single view, n_views = 1\n",
    "        features = features.view(batch_size * n_views, -1)\n",
    "        labels = labels.repeat(n_views)\n",
    "        similarity_matrix = torch.div(torch.matmul(features, features.T), self.temperature)\n",
    "        logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)\n",
    "        logits = similarity_matrix - logits_max.detach()\n",
    "        mask = torch.eq(labels.unsqueeze(1), labels.unsqueeze(0)).float().to(device)\n",
    "        # Remove self-comparisons from the mask.\n",
    "        logits_mask = torch.scatter(torch.ones_like(mask), 1,\n",
    "                                    torch.arange(batch_size * n_views).view(-1, 1).to(device), 0)\n",
    "        mask = mask * logits_mask\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)\n",
    "        mask_sum = mask.sum(1)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask_sum + 1e-12)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss\n",
    "\n",
    "# ============================================================\n",
    "# Test-Time Augmentation (TTA) Function\n",
    "# ============================================================\n",
    "def predict_with_tta(model, image, tta_transforms, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for transform in tta_transforms:\n",
    "            aug = transform(image=image)['image']\n",
    "            aug = aug.unsqueeze(0).to(device)\n",
    "            output = model(aug)\n",
    "            predictions.append(torch.softmax(output, dim=1).cpu().numpy())\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "tta_transforms = [\n",
    "    A.Compose([A.Resize(224, 224), ToTensorV2()]),\n",
    "    A.Compose([A.Resize(224, 224), A.HorizontalFlip(p=1.0), ToTensorV2()]),\n",
    "    # Add more TTA variations as desired.\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Training Function with Contrastive Loss, Self-Distillation & Dynamic LR\n",
    "# ============================================================\n",
    "def train_model(config, train_loader, val_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_classes = len(full_dataset.classes)\n",
    "    model = HybridPlantClassifier(num_classes=num_classes).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=config['epochs'])\n",
    "    \n",
    "    # Choose loss function based on config.\n",
    "    # For balanced data we use the standard CrossEntropyLoss with label smoothing.\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    \n",
    "    supcon_loss_fn = SupConLoss(temperature=0.07)\n",
    "    contrastive_weight = config.get(\"contrastive_weight\", 1.0)\n",
    "    distill_weight = config.get(\"distill_weight\", 0.5)\n",
    "    mixup_alpha = config.get(\"mixup_alpha\", 1.0)\n",
    "    cutmix_alpha = config.get(\"cutmix_alpha\", 1.0)\n",
    "    num_epochs = config['epochs']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # --- Classification Branch with MixUp/CutMix ---\n",
    "            if np.random.rand() < 0.5:\n",
    "                mixed_images, y_a, y_b, lam = mixup_data(images, labels, alpha=mixup_alpha)\n",
    "            else:\n",
    "                mixed_images, y_a, y_b, lam = cutmix_data(images, labels, alpha=cutmix_alpha)\n",
    "            outputs = model(mixed_images)\n",
    "            loss_ce = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "\n",
    "            # --- Contrastive Branch and Self-Distillation using Original Images ---\n",
    "            _, embeddings, distill_logits = model(images, return_features=True)\n",
    "            embeddings = embeddings.unsqueeze(1)  # Shape: [batch, 1, feature_dim]\n",
    "            loss_contrast = supcon_loss_fn(embeddings, labels)\n",
    "            loss_distill = F.kl_div(F.log_softmax(distill_logits, dim=1),\n",
    "                                    F.softmax(outputs, dim=1), reduction='batchmean')\n",
    "            \n",
    "            total_loss = loss_ce + contrastive_weight * loss_contrast + distill_weight * loss_distill\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            train_loss += total_loss.item() * batch_size\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            train_correct += (preds == y_a).sum().item()\n",
    "            train_total += batch_size\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(y_a.cpu().numpy())\n",
    "            pbar.set_postfix(loss=f\"{total_loss.item():.4f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_train_loss = train_loss / train_total\n",
    "        train_acc = train_correct / train_total\n",
    "        train_f1 = f1_score(train_labels, train_preds, average=\"weighted\")\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "\n",
    "        # --- Validation Phase (without MixUp/CutMix) ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                batch_size = labels.size(0)\n",
    "                val_loss += loss.item() * batch_size\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += batch_size\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        avg_val_loss = val_loss / val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        val_f1 = f1_score(val_labels, val_preds, average=\"weighted\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\\n\")\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# Evaluation Function (Test Set) with Optional Logits Adjustment\n",
    "# ============================================================\n",
    "def evaluate_model(model, loader, adjust_logits_flag=False, class_priors=None, return_acc=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            if adjust_logits_flag and (class_priors is not None):\n",
    "                outputs = adjust_logits(outputs, class_priors)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs)\n",
    "    acc = (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    if return_acc:\n",
    "        return acc\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\\n\")\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    all_labels_bin = label_binarize(all_labels, classes=range(len(full_dataset.classes)))\n",
    "    fpr, tpr, _ = roc_curve(all_labels_bin.ravel(), np.array(all_probs).ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def objective(trial):\n",
    "    config = {\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True),\n",
    "        \"epochs\": 6,\n",
    "        \"contrastive_weight\": trial.suggest_float(\"contrastive_weight\", 0.5, 2.0),\n",
    "        \"distill_weight\": trial.suggest_float(\"distill_weight\", 0.1, 1.0),\n",
    "        \"mixup_alpha\": trial.suggest_float(\"mixup_alpha\", 0.5, 2.0),\n",
    "        \"cutmix_alpha\": trial.suggest_float(\"cutmix_alpha\", 0.5, 2.0)\n",
    "    }\n",
    "    # For tuning, we use the standard train_loader.\n",
    "    model = train_model(config, train_loader, val_loader)\n",
    "    val_acc = evaluate_model(model, val_loader, return_acc=True)\n",
    "    trial.report(val_acc, step=0)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    return val_acc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(), pruner=HyperbandPruner())\n",
    "study.optimize(objective, n_trials=8)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "\n",
    "# Use the best hyperparameters from Optuna and increase epochs.\n",
    "best_config = study.best_params.copy()\n",
    "best_config[\"epochs\"] = 30  # Increase epochs as desired.\n",
    "\n",
    "# ----- Training (Single Stage) -----\n",
    "print(\"Training on Original (Balanced) Data:\")\n",
    "model_final = train_model(best_config, train_loader, val_loader)\n",
    "\n",
    "# Compute class priors from training targets for logits adjustment.\n",
    "train_targets = [full_dataset.targets[i] for i in train_dataset.indices]\n",
    "train_targets = np.array(train_targets)\n",
    "unique_classes = np.unique(train_targets)\n",
    "total_samples = len(train_targets)\n",
    "class_priors = [np.sum(train_targets == i) / total_samples for i in range(len(unique_classes))]\n",
    "print(\"Class Priors:\", class_priors)\n",
    "\n",
    "evaluate_model(model_final, test_loader, adjust_logits_flag=True, class_priors=class_priors)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6738219,
     "sourceId": 10849519,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
